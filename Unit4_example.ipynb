{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6954c199-04df-426d-8a4a-d861dbab122a",
   "metadata": {},
   "source": [
    "## Fine tuning with Distill HUBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e56553f-8c5b-4257-99e2-6ed0231fbc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "from datasets import load_dataset, Audio\n",
    "from transformers import AutoFeatureExtractor\n",
    "from transformers import AutoModelForAudioClassification\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d81274e8-71c6-4684-ab30-25e7425097a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05b3c09099141d99a6b88ba8a038c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/3.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834fda9192254d599d9b33e6eedfd594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset gtzan/all to /home/.cache/huggingface/datasets/marsyas___gtzan/all/0.0.0/8bd0e23c2d9b2be30d36bc6834319772dff22a3bd28527996612386cef003910...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d90eb57c18f455da5ecef8564b17067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.23G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset gtzan downloaded and prepared to /home/.cache/huggingface/datasets/marsyas___gtzan/all/0.0.0/8bd0e23c2d9b2be30d36bc6834319772dff22a3bd28527996612386cef003910. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5199797b66c14892b258ac54f7fd8041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['file', 'audio', 'genre'],\n",
       "        num_rows: 999\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtzan = load_dataset(\"marsyas/gtzan\", \"all\")\n",
    "gtzan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20edb113-0c26-4617-83a5-9ef09b69e70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['file', 'audio', 'genre'],\n",
       "        num_rows: 899\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['file', 'audio', 'genre'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtzan = gtzan[\"train\"].train_test_split(seed=42, shuffle=True, test_size=0.1)\n",
    "gtzan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2f93645-80ab-4a2a-a9e2-77b2d6ac3495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pop'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label_fn = gtzan[\"train\"].features[\"genre\"].int2str\n",
    "id2label_fn(gtzan[\"train\"][0][\"genre\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3280648-48ce-4c94-8f53-d02186196628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_audio():\n",
    "#     example = gtzan[\"train\"].shuffle()[0]\n",
    "#     audio = example[\"audio\"]\n",
    "#     return (\n",
    "#         audio[\"sampling_rate\"],\n",
    "#         audio[\"array\"],\n",
    "#     ), id2label_fn(example[\"genre\"])\n",
    "\n",
    "\n",
    "# with gr.Blocks() as demo:\n",
    "#     with gr.Column():\n",
    "#         for _ in range(4):\n",
    "#             audio, label = generate_audio()\n",
    "#             output = gr.Audio(audio, label=label)\n",
    "\n",
    "# demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44612231-4b60-42e2-8250-680529c6c090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64494b4598d84ee4adcccd108afd80f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/214 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"ntu-spml/distilhubert\"\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    model_id, do_normalize=True, return_attention_mask=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08a423ce-126b-46d2-8d6a-7f936cdc5702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_rate = feature_extractor.sampling_rate\n",
    "sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8772a7a-462e-4270-a63c-cb4909fa51de",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtzan = gtzan.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b4c52e2-d033-4c30-927f-e6f2b29c3b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': '/home/.cache/huggingface/datasets/downloads/extracted/b96ff32d83db7594c836f58f0a9202aa3f903426f5e00926246a317fa68f2686/genres/pop/pop.00098.wav',\n",
       " 'audio': {'path': '/home/.cache/huggingface/datasets/downloads/extracted/b96ff32d83db7594c836f58f0a9202aa3f903426f5e00926246a317fa68f2686/genres/pop/pop.00098.wav',\n",
       "  'array': array([ 0.0873509 ,  0.20183384,  0.4790867 , ..., -0.18743178,\n",
       "         -0.23294401, -0.13517427]),\n",
       "  'sampling_rate': 16000},\n",
       " 'genre': 7}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtzan[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83560330-a4f5-4fd3-b5f2-8d87a9781c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.000185, Variance: 0.0493\n"
     ]
    }
   ],
   "source": [
    "sample = gtzan[\"train\"][0][\"audio\"]\n",
    "\n",
    "print(f\"Mean: {np.mean(sample['array']):.3}, Variance: {np.var(sample['array']):.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ae720e5-e012-4a30-84af-c7e04d2c8204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs keys: ['input_values', 'attention_mask']\n",
      "Mean: -7.45e-09, Variance: 1.0\n"
     ]
    }
   ],
   "source": [
    "inputs = feature_extractor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"])\n",
    "\n",
    "print(f\"inputs keys: {list(inputs.keys())}\")\n",
    "\n",
    "print(\n",
    "    f\"Mean: {np.mean(inputs['input_values']):.3}, Variance: {np.var(inputs['input_values']):.3}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b759cbb-d271-4c58-98c7-d9490dd6e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_duration = 30.0\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays,\n",
    "        sampling_rate=feature_extractor.sampling_rate,\n",
    "        max_length=int(feature_extractor.sampling_rate * max_duration),\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "    )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66735270-2928-4027-822c-bfeaed0649cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/899 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['genre', 'input_values', 'attention_mask'],\n",
       "        num_rows: 899\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['genre', 'input_values', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtzan_encoded = gtzan.map(\n",
    "    preprocess_function, remove_columns=[\"audio\", \"file\"], batched=True, num_proc=1\n",
    ")\n",
    "gtzan_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62ff82c7-d011-470e-be11-f0f198c14f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtzan_encoded = gtzan_encoded.rename_column(\"genre\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6a9d07c-37d8-4f8c-b10e-992a727d2979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pop'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {\n",
    "    str(i): id2label_fn(i)\n",
    "    for i in range(len(gtzan_encoded[\"train\"].features[\"label\"].names))\n",
    "}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "id2label[\"7\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9536d7-2f74-4ad1-9961-fe647d47ae07",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d5deb3c-e043-4045-aefc-af2585819b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a0399da6964ef2bbee1198eed7e909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be77c8656934fd6b5d8ff1c1f34800f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/94.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at ntu-spml/distilhubert and are newly initialized: ['projector.bias', 'projector.weight', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(id2label)\n",
    "\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=num_labels,\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d9a2110-d05c-4be1-890a-70b7b97b9d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_id.split(\"/\")[-1]\n",
    "batch_size = 8\n",
    "gradient_accumulation_steps = 1\n",
    "num_train_epochs = 10\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-gtzan\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f726e7f1-00b1-40b0-8f6b-43d07b92ac24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e519c31d0294400493648609902eaff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00a9bfcf-e30d-4420-80b0-fa2d8c38cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b00078-1a41-4fa6-8a60-ad91c3b20650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/kurianbenoy/distilhubert-finetuned-gtzan into local empty directory.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='1130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  41/1130 02:35 < 1:12:27, 0.25 it/s, Epoch 0.35/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=gtzan_encoded[\"train\"],\n",
    "    eval_dataset=gtzan_encoded[\"test\"],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fdc475-e723-42b2-a190-f994bc3e2737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
